{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishikaMadireddy/neural_network_ICP6/blob/main/Rishika_Madireddy_ICP6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt-qb4GE6dt1",
        "outputId": "3c9030bc-1bcf-47c8-bb6c-d0301c544157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Found existing installation: keras 2.15.0\n",
            "Uninstalling keras-2.15.0:\n",
            "  Successfully uninstalled keras-2.15.0\n",
            "Found existing installation: pandas 2.0.3\n",
            "Uninstalling pandas-2.0.3:\n",
            "  Successfully uninstalled pandas-2.0.3\n",
            "Found existing installation: matplotlib 3.7.1\n",
            "Uninstalling matplotlib-3.7.1:\n",
            "  Successfully uninstalled matplotlib-3.7.1\n",
            "Found existing installation: scikit-learn 1.2.2\n",
            "Uninstalling scikit-learn-1.2.2:\n",
            "  Successfully uninstalled scikit-learn-1.2.2\n",
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.15.0\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.0.3\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.9.1\n",
            "  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.5.1\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.1) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.1) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Installing collected packages: keras, scikit-learn, pandas, matplotlib, tensorflow\n",
            "Successfully installed keras-2.15.0 matplotlib-3.9.1 pandas-2.0.3 scikit-learn-1.5.1 tensorflow-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow keras pandas matplotlib scikit-learn\n",
        "!pip install tensorflow==2.15.0 keras==2.15.0 pandas==2.0.3 matplotlib==3.9.1 scikit-learn==1.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPIqh0Fk6-Ub",
        "outputId": "eace2e8f-e559-44fb-8ed1-2c597b9d2431"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-3fbf3d7a66dd>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
            "<ipython-input-9-3fbf3d7a66dd>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "291/291 - 52s - loss: 0.8206 - accuracy: 0.6492 - 52s/epoch - 178ms/step\n",
            "144/144 - 5s - loss: 0.7462 - accuracy: 0.6750 - 5s/epoch - 33ms/step\n",
            "0.7461780309677124\n",
            "0.6749672293663025\n",
            "['loss', 'accuracy']\n",
            "[1 2 1 ... 2 0 2]\n",
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1573f0e170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 287ms/epoch - 287ms/step\n",
            "[0.5841687  0.14928442 0.2665469 ]\n",
            "Neutral\n",
            "744/744 - 102s - loss: 0.8219 - accuracy: 0.6466 - 102s/epoch - 137ms/step\n",
            "744/744 - 103s - loss: 0.8217 - accuracy: 0.6507 - 103s/epoch - 138ms/step\n",
            "744/744 - 101s - loss: 0.8228 - accuracy: 0.6437 - 101s/epoch - 136ms/step\n",
            "744/744 - 100s - loss: 0.8244 - accuracy: 0.6491 - 100s/epoch - 135ms/step\n",
            "744/744 - 107s - loss: 0.8168 - accuracy: 0.6468 - 107s/epoch - 144ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 101s - loss: 0.8229 - accuracy: 0.6492 - 101s/epoch - 136ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 100s - loss: 0.6740 - accuracy: 0.7104 - 100s/epoch - 134ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 97s - loss: 0.8198 - accuracy: 0.6489 - 97s/epoch - 130ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 95s - loss: 0.6795 - accuracy: 0.7074 - 95s/epoch - 128ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 99s - loss: 0.8282 - accuracy: 0.6446 - 99s/epoch - 133ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 93s - loss: 0.6796 - accuracy: 0.7121 - 93s/epoch - 125ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 106s - loss: 0.8226 - accuracy: 0.6477 - 106s/epoch - 142ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 100s - loss: 0.6720 - accuracy: 0.7116 - 100s/epoch - 134ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 103s - loss: 0.8247 - accuracy: 0.6464 - 103s/epoch - 138ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 97s - loss: 0.6684 - accuracy: 0.7206 - 97s/epoch - 130ms/step\n",
            "372/372 - 57s - loss: 0.8306 - accuracy: 0.6454 - 57s/epoch - 154ms/step\n",
            "372/372 - 54s - loss: 0.8240 - accuracy: 0.6460 - 54s/epoch - 146ms/step\n",
            "372/372 - 62s - loss: 0.8281 - accuracy: 0.6425 - 62s/epoch - 165ms/step\n",
            "372/372 - 56s - loss: 0.8308 - accuracy: 0.6441 - 56s/epoch - 150ms/step\n",
            "372/372 - 57s - loss: 0.8233 - accuracy: 0.6455 - 57s/epoch - 153ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 60s - loss: 0.8301 - accuracy: 0.6406 - 60s/epoch - 160ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 57s - loss: 0.6832 - accuracy: 0.7136 - 57s/epoch - 154ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 59s - loss: 0.8238 - accuracy: 0.6442 - 59s/epoch - 160ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 54s - loss: 0.6839 - accuracy: 0.7144 - 54s/epoch - 145ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 55s - loss: 0.8372 - accuracy: 0.6438 - 55s/epoch - 149ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 52s - loss: 0.6867 - accuracy: 0.7080 - 52s/epoch - 141ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 54s - loss: 0.8367 - accuracy: 0.6379 - 54s/epoch - 145ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 51s - loss: 0.6808 - accuracy: 0.7145 - 51s/epoch - 136ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 60s - loss: 0.8239 - accuracy: 0.6459 - 60s/epoch - 162ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 56s - loss: 0.6757 - accuracy: 0.7142 - 56s/epoch - 149ms/step\n",
            "186/186 - 35s - loss: 0.8490 - accuracy: 0.6383 - 35s/epoch - 190ms/step\n",
            "186/186 - 34s - loss: 0.8430 - accuracy: 0.6367 - 34s/epoch - 184ms/step\n",
            "186/186 - 35s - loss: 0.8389 - accuracy: 0.6371 - 35s/epoch - 187ms/step\n",
            "186/186 - 38s - loss: 0.8452 - accuracy: 0.6347 - 38s/epoch - 204ms/step\n",
            "186/186 - 36s - loss: 0.8434 - accuracy: 0.6351 - 36s/epoch - 193ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 37s - loss: 0.8478 - accuracy: 0.6337 - 37s/epoch - 198ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 32s - loss: 0.6971 - accuracy: 0.7062 - 32s/epoch - 171ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 38s - loss: 0.8382 - accuracy: 0.6400 - 38s/epoch - 206ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 33s - loss: 0.6918 - accuracy: 0.7065 - 33s/epoch - 177ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 38s - loss: 0.8561 - accuracy: 0.6285 - 38s/epoch - 207ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 32s - loss: 0.6935 - accuracy: 0.7016 - 32s/epoch - 172ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 35s - loss: 0.8520 - accuracy: 0.6327 - 35s/epoch - 187ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 33s - loss: 0.6868 - accuracy: 0.7091 - 33s/epoch - 175ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 36s - loss: 0.8405 - accuracy: 0.6359 - 36s/epoch - 193ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 33s - loss: 0.6760 - accuracy: 0.7103 - 33s/epoch - 175ms/step\n",
            "Epoch 1/2\n",
            "233/233 - 47s - loss: 0.8279 - accuracy: 0.6454 - 47s/epoch - 201ms/step\n",
            "Epoch 2/2\n",
            "233/233 - 41s - loss: 0.6802 - accuracy: 0.7117 - 41s/epoch - 175ms/step\n",
            "Best: 0.678467 using {'batch_size': 40, 'epochs': 2}\n"
          ]
        }
      ],
      "source": [
        "#1st question:\n",
        "\n",
        "\n",
        "import pandas as pd # Basic packages for creating dataframes and loading dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # Package for visualization\n",
        "import re # importing package for Regular expression operations\n",
        "from sklearn.model_selection import train_test_split # Package for splitting the data\n",
        "from sklearn.preprocessing import LabelEncoder # Package for conversion of categorical to Numerical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Tokenization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Add zeros or crop based on the length\n",
        "from tensorflow.keras.models import Sequential # Sequential Neural Network\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D # For layers in Neural Network\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import GridSearchCV # Import GridSearchCV\n",
        "\n",
        "\n",
        "# Load the dataset as a Pandas DataFrame\n",
        "path_to_csv = '/content/Sentiment (3) (2).csv'\n",
        "dataset = pd.read_csv(path_to_csv, header=0)\n",
        "\n",
        "# Select only the necessary columns 'text' and 'sentiment'\n",
        "mask = dataset.columns.isin(['text', 'sentiment'])\n",
        "data = dataset.loc[:, mask]\n",
        "\n",
        "# Keeping only the necessary columns\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ') # Removing Retweets\n",
        "\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ') # Maximum words is 2000 to tokenize sentence\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values) # Taking values to feature matrix\n",
        "X = pad_sequences(X) # Padding the feature matrix\n",
        "\n",
        "embed_dim = 128 # Dimension of the Embedded layer\n",
        "lstm_out = 196 # Long short-term memory (LSTM) layer neurons\n",
        "\n",
        "def createmodel():\n",
        "    model = Sequential() # Sequential Neural Network\n",
        "    model.add(Embedding(max_features, embed_dim, input_length = X.shape[1])) # input dimension 2000 Neurons, output dimension 128 Neurons\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) # Drop out 20%, 196 output Neurons, recurrent dropout 20%\n",
        "    model.add(Dense(3, activation='softmax')) # 3 output neurons[positive, Neutral, Negative], softmax as activation\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy']) # Compiling the model\n",
        "    return model\n",
        "\n",
        "labelencoder = LabelEncoder() # Applying label Encoding on the label matrix\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment']) # Fitting the model\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42) # 67% training data, 33% test data split\n",
        "\n",
        "batch_size = 32 # Batch size 32\n",
        "model = createmodel() # Function call to Sequential Neural Network\n",
        "model.fit(X_train, Y_train, epochs=1, batch_size=batch_size, verbose=2) # verbose the higher, the more messages\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size) # evaluating the model\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names) # metrics of the model\n",
        "print(integer_encoded)\n",
        "print(data['sentiment'])\n",
        "\n",
        "# Predicting on the text data\n",
        "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
        "sentence = tokenizer.texts_to_sequences(sentence) # Tokenizing the sentence\n",
        "sentence = pad_sequences(sentence, maxlen=X.shape[1], dtype='int32', value=0) # Padding the sentence\n",
        "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] # Predicting the sentence text\n",
        "sentiment = np.argmax(sentiment_probs)\n",
        "\n",
        "print(sentiment_probs)\n",
        "if sentiment == 0:\n",
        "    print(\"Neutral\")\n",
        "elif sentiment == 1:\n",
        "    print(\"Negative\")\n",
        "else:\n",
        "    print(\"Positive\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2nd  question:\n",
        "\n",
        "# Custom wrapper for Keras model\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class CustomKerasClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, build_fn=None, epochs=1, batch_size=32, verbose=1, **sk_params): # Use double underscores __init__\n",
        "        self.build_fn = build_fn\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "        self.sk_params = sk_params\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y, **kwargs):\n",
        "        self.model = self.build_fn()\n",
        "        return self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose, **kwargs)\n",
        "\n",
        "    def predict(self, X, **kwargs):\n",
        "        return self.model.predict(X, **kwargs)\n",
        "\n",
        "    def predict_proba(self, X, **kwargs):\n",
        "        return self.model.predict(X, **kwargs)\n",
        "\n",
        "    def score(self, X, y, **kwargs):\n",
        "        _, accuracy = self.model.evaluate(X, y, verbose=0)\n",
        "        return accuracy\n",
        "\n",
        "# Use the custom Keras classifier\n",
        "model = CustomKerasClassifier(build_fn=createmodel, verbose=2)\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [1, 2]\n",
        "param_grid = {'batch_size': batch_size, 'epochs': epochs}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGpdIL2dnfWbz0zL1DumWQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}